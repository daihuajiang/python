{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ea1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "#from tensorflow.data import Dataset as tfds\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import IPython\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "#import tensorflow.datasets as tfds\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f96073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機產產生30張圖片的function\n",
    "def generate_images():\n",
    "    #隨機產生noise\n",
    "    glabels = np.zeros(30)\n",
    "    for i in range(30):\n",
    "        if i%10==0:\n",
    "            glabels[i]=0\n",
    "        if i%10==1:\n",
    "            glabels[i]=1\n",
    "        if i%10==2:\n",
    "            glabels[i]=2\n",
    "\n",
    "    #產生圖片\n",
    "    noise = tf.random.normal([30, latent_dim])\n",
    "    generated_images = (conditional_gen([glabels,noise]))\n",
    "\n",
    "    #將generated_images值縮為0-1\n",
    "    immax = np.max(generated_images)\n",
    "    immin = np.min(generated_images)\n",
    "    if immin < 0:\n",
    "        generated_images += abs(immin)\n",
    "    generated_images /= (immax - immin)\n",
    "    \n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3589e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#印出10張圖片的function\n",
    "def display_3class(array1, savepath):\n",
    "    n = 10\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        plt.imshow(array1[i])\n",
    "        plt.title('cat')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(array1[i+10])\n",
    "        plt.title('dog')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(array1[i+20])\n",
    "        plt.title('panda')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.gcf()\n",
    "    plt.savefig(savepath)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdb9e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "conditional_gen = tf.keras.models.load_model('generator.h5')\n",
    "conditional_discriminator = tf.keras.models.load_model('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5070cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用於儲存d和g的loss\n",
    "d1_loss = 0\n",
    "d2_loss = 0\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "#define train_step\n",
    "# Notice the use of `tf.function`. This annotation causes the function to be \"compiled\".\n",
    "@tf.function(tf.config.run_functions_eagerly(True))\n",
    "def train_step(images,target):\n",
    "    # noise vector sampled from normal distribution\n",
    "    noise = tf.random.normal([target.shape[0], latent_dim])\n",
    "    # Train Discriminator with real labels\n",
    "    with tf.GradientTape() as disc_tape1:\n",
    "        generated_images = conditional_gen([target,noise], training=True)\n",
    "\n",
    "        real_output = conditional_discriminator([images,target], training=True)\n",
    "        real_targets = tf.ones_like(real_output)\n",
    "        disc_loss1 = discriminator_loss(real_targets, real_output)\n",
    "        d1_loss = disc_loss1.numpy()\n",
    "        \n",
    "    # gradient calculation for discriminator for real labels    \n",
    "    gradients_of_disc1 = disc_tape1.gradient(disc_loss1, conditional_discriminator.trainable_variables)\n",
    "    \n",
    "    # parameters optimization for discriminator for real labels   \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_disc1,\\\n",
    "    conditional_discriminator.trainable_variables))\n",
    "    \n",
    "    # Train Discriminator with fake labels\n",
    "    with tf.GradientTape() as disc_tape2:\n",
    "        fake_output = conditional_discriminator([generated_images,target], training=True)\n",
    "        fake_targets = tf.zeros_like(fake_output)\n",
    "        disc_loss2 = discriminator_loss(fake_targets, fake_output)\n",
    "        d2_loss = disc_loss2.numpy()\n",
    "        \n",
    "    #\n",
    "    d_loss.append(d1_loss + d2_loss)\n",
    "    \n",
    "    # gradient calculation for discriminator for fake labels \n",
    "    gradients_of_disc2 = disc_tape2.gradient(disc_loss2, conditional_discriminator.trainable_variables)\n",
    "    \n",
    "    \n",
    "    # parameters optimization for discriminator for fake labels        \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_disc2,\\\n",
    "    conditional_discriminator.trainable_variables))\n",
    "    \n",
    "    \n",
    "    # Train Generator with real labels\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = conditional_gen([target,noise], training=True)\n",
    "        fake_output = conditional_discriminator([generated_images,target], training=True)\n",
    "        real_targets = tf.ones_like(fake_output)\n",
    "        gen_loss = generator_loss(real_targets, fake_output)\n",
    "        g_loss.append(gen_loss.numpy())\n",
    "\n",
    "    # gradient calculation for generator for real labels     \n",
    "    gradients_of_gen = gen_tape.gradient(gen_loss, conditional_gen.trainable_variables)\n",
    "    \n",
    "    \n",
    "    # parameters optimization for generator for real labels\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_gen,\\\n",
    "    conditional_gen.trainable_variables))  \n",
    "    \n",
    "    \n",
    "    #print(\"g_loss: {gen_loss}, d_loss: {disc_total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cbe850",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-498d760af38e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#train\n",
    "import time\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        iteration = 0\n",
    "        start = time.time()\n",
    "        for image_batch in dataset:\n",
    "            img = tf.cast(image_batch[0], tf.float32)\n",
    "            #imgs = normalization(img)\n",
    "            imgs = img\n",
    "            train_step(imgs, image_batch[1])\n",
    "            print ('epoch {}, {}/{}, g_loss: {} d_loss: {}'.format(epoch + 1, iteration+1, len(dataset), g_loss[-1], d_loss[-1]))\n",
    "            iteration+=1\n",
    "        \n",
    "        conditional_gen.save('generator.h5')\n",
    "        conditional_discriminator.save('discriminator.h5')\n",
    "        print('epoch{}: {}sec\\n'.format(epoch+1, round(time.time()-start)))\n",
    "        \n",
    "        if epoch%10==0 or epoch%epochs==0:\n",
    "            epoch_imgs = generate_images()\n",
    "            savepath =  \"./animal_generate/epoch_\"+str(epoch)+\"_animals_generate.jpg\" \n",
    "            display_3class(epoch_imgs, savepath)\n",
    "              \n",
    "epoch = 200\n",
    "train(dataset, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d22e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
